Download Link: https://assignmentchef.com/product/solved-sml-assignment-3
<br>
Q1. Let <strong>x </strong>be a d-dimensional binary vector with a multivariate Bernoulli distribution

<em>d</em>

<em>P</em>(<strong>x</strong>|<em>θ</em>) = Y<em>θ</em><em>ix</em><em>i</em>(1 − <em>θ</em><em>i</em>)1−<em>x</em><em>i                                                                          </em>(1)

<em>i</em>=1

where <em>θ </em>= (<em>θ</em><sub>1</sub><em>,…,θ<sub>d</sub></em>)<em><sup>t </sup></em>is an unknown parameter vector, <em>θ<sub>i </sub></em>being the probability that <em>x<sub>i </sub></em>= 1. Show that the maximum likelihood estimate for <em>θ </em>is

(2)

Q2. Show that if our model is poor, the maximum likelihood classifier we derive is not the best by exploring the following example. Suppose we have two equally probable categories. Further, we know that <em>p</em>(<em>x</em>|<em>ω</em><sub>1</sub>)<em>N</em>˜(0<em>,</em>1) but assume that <em>p</em>(<em>x</em>|<em>ω</em><sub>2</sub>)<em>N</em>˜(<em>µ,</em>1). Image however that the true underlying distribution is <em>p</em>(<em>x</em>|<em>ω</em><sub>2</sub>)<em>N</em><sup>˜</sup>(1<em>,</em>10<sup>6</sup>).

<ol>

 <li>What is the value of maximum likelihood estimation <em>µ<sub>ML </sub></em>in our poor</li>

</ol>

model, given a large amount of data?

<ol>

 <li>What is the decision boundary arising from this maximum likelihood</li>

</ol>

estimate in the poor model?

<ol>

 <li>Give an expression for the optimal Bayes decision boundary given thetrue underlying distributions <em>p</em>(<em>x</em>|<em>ω</em><sub>1</sub>)<em>N</em><sup>˜</sup>(0<em>,</em>1) and <em>p</em>(<em>x</em>|<em>ω</em><sub>2</sub>)<em>N</em><sup>˜</sup>(<em>µ,</em>1). Compare this with part b.</li>

</ol>

Q3. Suppose we employ a novel method for estimating the mean of a data set D = <em>x</em><sub>1</sub><em>,x</em><sub>2</sub><em>,…,x<sub>n</sub></em>; we assign the mean to be the value of the first point in the set ie. <em>x</em><sub>1</sub>.

<ol>

 <li>Show that this method is unbiased.</li>

 <li>State why this method is nevertheless highly undesirable.</li>

</ol>

Ungraded

Q4. Derive MLE for Binomial distribution <em>X Bin</em>(<em>N,µ</em>)

<em>P</em>(<em>X </em>= <em>m</em>) = (<em>N<sub>Cm</sub></em>)<em>µ<sup>m</sup></em>(1 − <em>µ</em>)<em><sup>N</sup></em><sup>−<em>m                                                                 </em></sup>(3)

The distribution gives the probability of observing <em>m </em>successes (say heads) in <em>N </em>independent Bernoulli trials. Since the heads can appear anywhere, <em>N<sub>Cm </sub></em>is the normalizing factor.

1